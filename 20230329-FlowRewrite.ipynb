{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import queue, threading, time\n",
    "from configparser import ConfigParser\n",
    "from numpy.core.numeric import zeros_like\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import math\n",
    "import random\n",
    "from vidgear.gears import VideoGear\n",
    "from vidgear.gears import WriteGear\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#hsv transform to rgb format\n",
    "def hsv2rgb(h,s,v):\n",
    "    return tuple(round(i * 255) for i in colorsys.hsv_to_rgb(h,s,v))\n",
    "\n",
    "# 自定义卷积函数\n",
    "def my_conv(input, kernel, step):\n",
    "    output_size_0 = int((len(input) - len(kernel)) / step + 1)   # 输出结果的第0维长度\n",
    "    output_size_1 = int((len(input[0]) - len(kernel[0])) / step + 1)   # 输出结果的第1维长度\n",
    "    res = np.zeros([output_size_0, output_size_1], np.float32)\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        for j in range(len(res[0])):\n",
    "            a = input[i*step:i*step + len(kernel), j*step: j*step + len(kernel)]  # 从输入矩阵中取出子矩阵\n",
    "            b = a * kernel  # 对应元素相乘\n",
    "            res[i][j] = b.sum()   \n",
    "    return res\n",
    "\n",
    "# 自定义鼠标双击事件——获取图像坐标\n",
    "# 1. 对图像进行操作，同时生成一副新的图像；\n",
    "# maybe需要多线程\n",
    "frame_cur = 0\n",
    "horMat = 0\n",
    "verMat = 0\n",
    "mag = 0\n",
    "# 自定义鼠标事件，获取该点的displacement\n",
    "def on_EVENT_LBUTTONDOWN(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        xy = \"%d,%d\" % (x, y)\n",
    "        mag_value       = mag[y, x]\n",
    "        horMat_value    = horMat[y, x]\n",
    "        verMat_value    = verMat[y, x]\n",
    "        \n",
    "        cv2.circle(frame_cur, (x-1, y-1), 2, (0, 0, 255), thickness = -1)\n",
    "        if x < 650:\n",
    "            cv2.putText(frame_cur, \"x:{},y:{}\".format(x,y), (x+10, y+10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1, (0,0,0), thickness = 2)\n",
    "            cv2.putText(frame_cur, \"dis is:{:.4f},{:.4f},{:.4f}\".format(mag_value, horMat_value, verMat_value), (x+10, y+25), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1, (0,0,0), thickness = 2)    \n",
    "        else:\n",
    "            cv2.putText(frame_cur, \"x:{},y:{}\".format(x,y), (x-100, y+10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1, (0,0,0), thickness = 2)    \n",
    "            cv2.putText(frame_cur, \"dis is:{:.4f},{:.4f},{:.4f}\".format(mag_value, horMat_value, verMat_value), (x-260, y+25), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1, (0,0,0), thickness = 2)    \n",
    "        \n",
    "        cv2.imshow(\"Orignal\", frame_cur)\n",
    "        if cv2.waitKey() & 0xFF ==27 :\n",
    "            print(\"Continue Play!\")\n",
    "cv2.namedWindow('Orignal', cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback(\"Orignal\", on_EVENT_LBUTTONDOWN)\n",
    "\n",
    "# 2. 对视频实施爬取，读取连续图像，并且可以生成曲线图；\n",
    "# maybe需要多线程\n",
    "# 还没想好\n",
    "# 拆解成1. 固定点的位置抓取；2. 逐帧抓取数据\n",
    "# 2. 逐帧抓取数据（可以用来对光流算法！！参数进行分析）\n",
    "\n",
    "\n",
    "# 导出mag ang数据\n",
    "def save_mag_ang(mag, ang):\n",
    "    # 绘制magnitude图片\n",
    "    print(\"mag.shape: \", np.shape(mag))\n",
    "    timeNow = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    os.makedirs(\"save_\" + timeNow)\n",
    "    np.savetxt(\"save_\" + timeNow + \"/mag.txt\", mag)\n",
    "    np.savetxt(\"save_\" + timeNow + \"/angle.txt\", ang)\n",
    "    \n",
    "# 读取mag or ang数据\n",
    "def read_mag_ang(txtPath):\n",
    "    return np.loadtxt(txtPath)\n",
    "\n",
    "# 分析背景噪声，使用直方图法分析所有点的矢量（包括对不同区域的分析）\n",
    "\n",
    "\n",
    "# 去噪，并计算PDE的方法\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前使用[800, 600]分辨率显示视频；相机视频流还待开发；需要编写接口使其适配各种分辨率；\n",
    "# 开发分析mag的接口；\n",
    "# 图形化分析：1. 鼠标事件，用矩形框抓取区域内的矢量参数； 2. 鼠标事件，固定鼠标位置，逐帧抓取该点矢量参数，并绘制曲线图； 3. 鼠标事件，固定矩形框区域，逐帧抓取该区域矢量参数，并绘制曲线图；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control parameters\n",
    "is_save_stream = False\n",
    "is_anti_shake = False\n",
    "is_ref_refresh = is_anti_shake\n",
    "is_change_size = True\n",
    "\n",
    "# default parameters  \n",
    "# calculation parameters\n",
    "winsize = 64\n",
    "mag_ceiling = 0.5\n",
    "mag_floor = mag_ceiling/5\n",
    "\n",
    "# camer & image parameters\n",
    "alpha = 0.8 \n",
    "hue = 90                     \n",
    "RES=(1920,1080)                 # camera resolution\n",
    "# roi_rect = [0,RES[0],0,RES[1]]  # region of interesting\n",
    "roi_rect = [200,600,115,420] # 转置前\n",
    "\n",
    "result_RES = (1080, 720)         # flow image resolution\n",
    "# options = {\"CAP_PROP_FRAME_WIDTH\":2592, \"CAP_PROP_FRAME_HEIGHT\":1944, \"CAP_PROP_FPS\":30}\n",
    "options = {\"CAP_PROP_FRAME_WIDTH\":800, \"CAP_PROP_FRAME_HEIGHT\":600, \"CAP_PROP_FPS\":30}\n",
    "# stable calculation parameters\n",
    "pyr_scale = 0.5\n",
    "levels = 2\n",
    "iterations = 1\n",
    "poly_n = 5\n",
    "poly_sigma = 1.1\n",
    "flags = cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
    "Noffset = 30 # 消除光流算法偏差的位移量\n",
    "# drawing buffer\n",
    "ax = []\n",
    "ay1 = []\n",
    "ay2 = [] \n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video resolution is (height, width, channel) :  (1944, 2592, 3)\n",
      "begin stream!\n",
      "1 times\n",
      "2 times\n",
      "3 times\n",
      "4 times\n",
      "5 times\n",
      "6 times\n",
      "7 times\n",
      "8 times\n",
      "9 times\n",
      "10 times\n",
      "11 times\n",
      "12 times\n",
      "13 times\n",
      "14 times\n",
      "15 times\n",
      "16 times\n",
      "17 times\n",
      "18 times\n",
      "19 times\n",
      "20 times\n",
      "21 times\n",
      "22 times\n",
      "23 times\n",
      "24 times\n",
      "25 times\n",
      "26 times\n",
      "27 times\n",
      "28 times\n",
      "29 times\n",
      "30 times\n",
      "31 times\n",
      "32 times\n",
      "33 times\n",
      "34 times\n",
      "35 times\n",
      "36 times\n",
      "37 times\n",
      "38 times\n",
      "39 times\n",
      "40 times\n",
      "41 times\n",
      "42 times\n",
      "43 times\n",
      "44 times\n",
      "45 times\n",
      "46 times\n",
      "47 times\n",
      "48 times\n",
      "49 times\n",
      "50 times\n",
      "51 times\n",
      "52 times\n",
      "53 times\n",
      "54 times\n",
      "55 times\n",
      "56 times\n",
      "57 times\n",
      "58 times\n",
      "59 times\n",
      "nothing wrong!\n",
      "60 times\n",
      "nothing wrong!\n",
      "61 times\n",
      "nothing wrong!\n",
      "62 times\n",
      "nothing wrong!\n",
      "63 times\n",
      "nothing wrong!\n",
      "64 times\n",
      "nothing wrong!\n",
      "65 times\n",
      "nothing wrong!\n",
      "66 times\n",
      "nothing wrong!\n",
      "67 times\n",
      "nothing wrong!\n",
      "68 times\n",
      "nothing wrong!\n",
      "69 times\n",
      "nothing wrong!\n",
      "70 times\n",
      "nothing wrong!\n",
      "71 times\n",
      "nothing wrong!\n",
      "72 times\n",
      "nothing wrong!\n",
      "73 times\n",
      "nothing wrong!\n",
      "74 times\n",
      "nothing wrong!\n",
      "75 times\n",
      "nothing wrong!\n",
      "76 times\n",
      "nothing wrong!\n",
      "77 times\n",
      "nothing wrong!\n",
      "78 times\n",
      "nothing wrong!\n",
      "79 times\n",
      "nothing wrong!\n",
      "80 times\n",
      "nothing wrong!\n",
      "81 times\n",
      "nothing wrong!\n",
      "82 times\n",
      "nothing wrong!\n",
      "83 times\n",
      "nothing wrong!\n",
      "84 times\n",
      "nothing wrong!\n",
      "85 times\n",
      "nothing wrong!\n",
      "86 times\n",
      "nothing wrong!\n",
      "87 times\n",
      "nothing wrong!\n",
      "88 times\n",
      "nothing wrong!\n",
      "89 times\n",
      "nothing wrong!\n",
      "90 times\n",
      "nothing wrong!\n",
      "91 times\n",
      "nothing wrong!\n",
      "92 times\n",
      "nothing wrong!\n",
      "93 times\n",
      "nothing wrong!\n",
      "94 times\n",
      "nothing wrong!\n",
      "95 times\n",
      "nothing wrong!\n",
      "96 times\n",
      "nothing wrong!\n",
      "97 times\n",
      "nothing wrong!\n",
      "98 times\n",
      "nothing wrong!\n",
      "99 times\n",
      "nothing wrong!\n",
      "100 times\n",
      "nothing wrong!\n",
      "101 times\n",
      "nothing wrong!\n",
      "102 times\n",
      "nothing wrong!\n",
      "103 times\n",
      "nothing wrong!\n",
      "104 times\n",
      "nothing wrong!\n",
      "105 times\n",
      "nothing wrong!\n",
      "106 times\n",
      "nothing wrong!\n",
      "107 times\n",
      "nothing wrong!\n",
      "108 times\n",
      "nothing wrong!\n",
      "109 times\n",
      "nothing wrong!\n",
      "110 times\n",
      "nothing wrong!\n",
      "111 times\n",
      "nothing wrong!\n",
      "112 times\n",
      "nothing wrong!\n",
      "113 times\n",
      "nothing wrong!\n",
      "114 times\n",
      "nothing wrong!\n",
      "115 times\n",
      "nothing wrong!\n",
      "116 times\n",
      "nothing wrong!\n",
      "117 times\n",
      "nothing wrong!\n",
      "118 times\n",
      "nothing wrong!\n",
      "119 times\n",
      "nothing wrong!\n",
      "120 times\n",
      "nothing wrong!\n",
      "121 times\n",
      "nothing wrong!\n",
      "122 times\n",
      "nothing wrong!\n",
      "123 times\n",
      "nothing wrong!\n",
      "124 times\n",
      "nothing wrong!\n",
      "125 times\n",
      "nothing wrong!\n",
      "126 times\n",
      "nothing wrong!\n",
      "127 times\n",
      "nothing wrong!\n",
      "128 times\n",
      "nothing wrong!\n",
      "129 times\n",
      "nothing wrong!\n",
      "130 times\n",
      "nothing wrong!\n",
      "131 times\n",
      "nothing wrong!\n",
      "132 times\n",
      "nothing wrong!\n",
      "133 times\n",
      "nothing wrong!\n",
      "134 times\n",
      "nothing wrong!\n",
      "135 times\n",
      "nothing wrong!\n",
      "136 times\n",
      "nothing wrong!\n",
      "137 times\n",
      "nothing wrong!\n",
      "138 times\n",
      "nothing wrong!\n",
      "139 times\n",
      "nothing wrong!\n",
      "140 times\n",
      "nothing wrong!\n",
      "141 times\n",
      "nothing wrong!\n",
      "142 times\n",
      "nothing wrong!\n",
      "143 times\n",
      "nothing wrong!\n",
      "144 times\n",
      "nothing wrong!\n",
      "145 times\n",
      "nothing wrong!\n",
      "146 times\n",
      "nothing wrong!\n",
      "147 times\n",
      "nothing wrong!\n",
      "148 times\n",
      "nothing wrong!\n",
      "149 times\n",
      "nothing wrong!\n",
      "150 times\n",
      "nothing wrong!\n",
      "151 times\n",
      "nothing wrong!\n",
      "152 times\n",
      "nothing wrong!\n",
      "153 times\n",
      "nothing wrong!\n",
      "154 times\n",
      "nothing wrong!\n",
      "155 times\n",
      "nothing wrong!\n",
      "156 times\n",
      "nothing wrong!\n",
      "157 times\n",
      "nothing wrong!\n",
      "158 times\n",
      "nothing wrong!\n",
      "159 times\n",
      "nothing wrong!\n",
      "160 times\n",
      "nothing wrong!\n",
      "161 times\n",
      "nothing wrong!\n",
      "162 times\n",
      "nothing wrong!\n",
      "163 times\n",
      "nothing wrong!\n",
      "164 times\n",
      "nothing wrong!\n",
      "165 times\n",
      "nothing wrong!\n",
      "166 times\n",
      "nothing wrong!\n",
      "167 times\n",
      "nothing wrong!\n",
      "168 times\n",
      "nothing wrong!\n",
      "169 times\n",
      "nothing wrong!\n",
      "170 times\n",
      "nothing wrong!\n",
      "171 times\n",
      "nothing wrong!\n",
      "172 times\n",
      "nothing wrong!\n",
      "173 times\n",
      "nothing wrong!\n",
      "174 times\n",
      "nothing wrong!\n",
      "175 times\n",
      "nothing wrong!\n",
      "176 times\n",
      "nothing wrong!\n",
      "177 times\n",
      "nothing wrong!\n",
      "178 times\n",
      "nothing wrong!\n",
      "179 times\n",
      "nothing wrong!\n",
      "180 times\n",
      "nothing wrong!\n",
      "181 times\n",
      "nothing wrong!\n",
      "182 times\n",
      "nothing wrong!\n",
      "183 times\n",
      "nothing wrong!\n",
      "184 times\n",
      "nothing wrong!\n",
      "185 times\n",
      "nothing wrong!\n",
      "186 times\n",
      "nothing wrong!\n",
      "187 times\n",
      "nothing wrong!\n",
      "188 times\n",
      "nothing wrong!\n",
      "189 times\n",
      "video has played over!\n"
     ]
    }
   ],
   "source": [
    "# 水平噪声、数值噪声\n",
    "# stream = VideoGear(source=\"./WIN_20230329_16_13_08_Pro.mp4\", stabilize= is_anti_shake , resolution=RES, **options).start()\n",
    "stream = VideoGear(source=\"./WIN_20230329_16_13_08_Pro.mp4\", stabilize= is_anti_shake , resolution=RES, **options).start()\n",
    "\n",
    "# pre-read frame\n",
    "frame_pre = stream.read()\n",
    "print(\"video resolution is (height, width, channel) : \",frame_pre.shape)\n",
    "bgr_pre = cv2.cvtColor(frame_pre, cv2.COLOR_BGR2GRAY)\n",
    "# initial hsv\n",
    "hsv = np.zeros_like(frame_pre)  \n",
    "# hsv = np.zeros_like(frame_pre[roi_rect[2]:roi_rect[3],roi_rect[0]:roi_rect[1]])  \n",
    "hsv[...,1] = 255 #saturation is full\n",
    "blank = np.zeros_like(frame_pre)\n",
    "\n",
    "# video loop\n",
    "count = 0\n",
    "print(\"begin stream!\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        frame_cur = stream.read()\n",
    "        if frame_cur is None:\n",
    "            print(\"video has played over!\")\n",
    "            break\n",
    "        count += 1\n",
    "        if count < 60:\n",
    "            print(\"%d times\"% count)\n",
    "            continue\n",
    "        bgr_cur = cv2.cvtColor(frame_cur, cv2.COLOR_BGR2GRAY) # change in to gray\n",
    "        # 测量两幅同样图像\n",
    "        if is_ref_refresh:\n",
    "            bgr_pre = bgr_cur\n",
    "        \n",
    "        if is_change_size:\n",
    "            # 改变图像大小\n",
    "            # resize_resolution = [1296, 972]    \n",
    "            resize_resolution   = [800, 600]\n",
    "            frame_pre           = cv2.resize(frame_pre ,resize_resolution)\n",
    "            frame_cur           = cv2.resize(frame_cur ,resize_resolution)\n",
    "            bgr_pre             = cv2.resize(bgr_pre ,resize_resolution)\n",
    "            bgr_cur             = cv2.resize(bgr_cur ,resize_resolution)\n",
    "            hsv                 = cv2.resize(hsv ,resize_resolution)\n",
    "            blank               = cv2.resize(blank ,resize_resolution)\n",
    "        \n",
    "        # 图像裁切\n",
    "        roi_bgr_pre = bgr_pre\n",
    "        roi_bgr_cur = bgr_cur\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(roi_bgr_pre,roi_bgr_cur, None,\n",
    "                                        pyr_scale,\n",
    "                                        levels,\n",
    "                                        winsize,\n",
    "                                        iterations,\n",
    "                                        poly_n,\n",
    "                                        poly_sigma,\n",
    "                                        flags)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])  # orginal flow\n",
    "        # 结果矩阵为mag，调用到鼠标事件中\n",
    "        \n",
    "        # 绘制矢量箭头方案一：opencv-arrowedline\n",
    "        min_arrowline_threshold = 1.5   # 矢量箭头阈值下限（与矢量平均值相除）\n",
    "        max_arrowline_threshold = 10    # 矢量箭头阈值下限\n",
    "        step = 20                       # 卷积模板步长\n",
    "        half_step = int(step/2)         # 卷积模板的半步长\n",
    "        # 1. 确定要画的mag及其坐标\n",
    "        mag_mean = cv2.mean(mag)[0]\n",
    "        mag = np.where(mag > min_arrowline_threshold * mag_mean, mag, 0)\n",
    "        mag = np.where(mag < max_arrowline_threshold * mag_mean, mag, 0)\n",
    "        kernel = np.ones((half_step, half_step)) / half_step**2\n",
    "        mag_conv = my_conv(mag, kernel, step)\n",
    "        ang_conv = my_conv(ang, kernel, step)\n",
    "        \n",
    "        horMat = np.multiply(mag_conv, np.cos(ang_conv))\n",
    "        verMat = np.multiply(mag_conv, np.sin(ang_conv))\n",
    "        # 2. 卷积形成矢量箭头\n",
    "        for index, value in np.ndenumerate(mag_conv):\n",
    "            if value != 0.0:\n",
    "                # print(index, value, horMat[index], verMat[index])\n",
    "                cv2.arrowedLine(frame_cur, (index[1]*step, index[0]*step) ,(index[1]*step+int(horMat[index]*step), index[0]*step+int(verMat[index]*step)), (255, 0, 0), 2, 9, 0, 0.3)  # 画箭头\n",
    "        \n",
    "        \n",
    "        mag_sft = abs(mag - mag_mean)  # shifted magnitude to elimiate noise\n",
    "        hsv[...,0] = (ang + hue)*180/np.pi/2 # color space related to angle \n",
    "        hsv[...,2] = cv2.normalize(mag_sft,None,0,255,cv2.NORM_MINMAX) \n",
    "        bgr_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        #enhanced flow\n",
    "        mag_enhanced = zeros_like(mag_sft)\n",
    "        cv2.min(mag_sft,mag_ceiling,mag_enhanced)  # enhance flow, ceiling and flooring\n",
    "        cv2.max(mag_enhanced,mag_floor,mag_enhanced)\n",
    "        hsv[...,0] = (ang + hue)*180/np.pi/2 # color space related to angle \n",
    "        hsv[...,2] = cv2.normalize(mag_enhanced,None,0,255,cv2.NORM_MINMAX)\n",
    "        bgr_flow_enhanced = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # image emerge with enhanced flow\n",
    "        flow_blend_enhance = cv2.addWeighted(frame_cur, 1-alpha ,bgr_flow_enhanced,  alpha, 0)\n",
    "        bgr_blend = cv2.addWeighted(frame_cur, 1-alpha ,bgr_flow,  alpha, 0)\n",
    "        frame_blend = flow_blend_enhance\n",
    "        \n",
    "        if is_ref_refresh:\n",
    "            bgr_pre = bgr_cur\n",
    "        \n",
    "        #palette\n",
    "        palette=np.zeros((512,512,3),np.uint8)\n",
    "        mag_norm = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        mag_min,mag_max,min_indx,max_indx=cv2.minMaxLoc(mag)\n",
    "        ang_mean = cv2.mean(ang*mag/mag_mean)[0]\n",
    "\n",
    "        # 对结果矩阵偏移的修正\n",
    "        horMat = np.multiply(mag, np.cos(ang))\n",
    "        verMat = np.multiply(mag, np.sin(ang))\n",
    "\n",
    "        # 计算水平噪声最大值和竖直噪声最大值\n",
    "        _,hor_MaxNoise, _, _ = cv2.minMaxLoc(np.multiply(mag, np.cos(ang)))\n",
    "        _,ver_MaxNoise, _, _ = cv2.minMaxLoc(np.multiply(mag, np.sin(ang)))\n",
    "\n",
    "\n",
    "        # 计算水平噪声和竖直噪声\n",
    "        hor_Noise = np.average(np.multiply(mag, np.cos(ang)))\n",
    "        ver_Noise = np.average(np.multiply(mag, np.sin(ang)))\n",
    "        # # 绝对值计算水平噪声和竖直噪声\n",
    "        # hor_AbsNoise = np.average(np.abs(horMat))\n",
    "        # ver_AbsNoise = np.average(np.abs(verMat))\n",
    "\n",
    " \n",
    "    except Exception:\n",
    "        # read current frame from cap\n",
    "        print(\"something wrong!\")\n",
    "        stream.stop()  \n",
    "        raise\n",
    "    \n",
    "    else:\n",
    "        # # result flow image\n",
    "        print(\"nothing wrong!\")\n",
    "        print(\"%d times\"% count)\n",
    "        # palette show\n",
    "        cv2.putText(palette, \"max=\"+str(mag.max()), (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"mag_mean=\"+str(\"%.7f\"%mag_mean), (0, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"mag_max=\"+str(mag_max), (0, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"mag_min=\"+str(mag_min), (0, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"hor_Noise=\"+str(hor_Noise), (0, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"ver_Noise=\"+str(ver_Noise), (0, 180), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"hor_MaxNoise=\"+str(hor_MaxNoise), (0, 210), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        cv2.putText(palette, \"ver_MaxNoise=\"+str(ver_MaxNoise), (0, 240), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "        # original show\n",
    "        # cv2.imshow('Orignal',cv2.resize(frame_cur, (result_RES[0], result_RES[1]))) # resize函数的显示窗口会对鼠标事件产生干扰！\n",
    "        cv2.putText(frame_cur, \"Frame is:{} \".format(count), (10, 35), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        3.0, (0,0,0), thickness = 3) \n",
    "        \n",
    "        cv2.imshow('Orignal', frame_cur)\n",
    "        cv2.imshow(\"Palette\", palette)\n",
    "        cv2.imshow('Blender', cv2.resize(bgr_blend , (result_RES[0], result_RES[1])))\n",
    "        cv2.imshow('Area of Intrest Blended', cv2.resize(frame_blend  , (result_RES[0], result_RES[1])))\n",
    "        \n",
    "        # keyboard event\n",
    "        # key 'r'   : refresh img\n",
    "        # key 'q'   : quit\n",
    "        # key 'ESC' : quit mouse event\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"r\"):\n",
    "            bgr_pre = bgr_cur\n",
    "            print(\"Background Refresh!\")\n",
    "        if key == ord(\"q\"):\n",
    "            print(\"KeyboardInterrupt!\")\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "stream.stop()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9.).reshape(3, 3)\n",
    "np.where(x < 5, x, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video resolution is (height, width, channel) :  (1944, 2592, 3)\n",
      "begin stream!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 水平噪声、数值噪声\n",
    "stream = VideoGear(source=\"./WIN_20230329_16_13_08_Pro.mp4\", stabilize= is_anti_shake , resolution=RES, **options).start()\n",
    "\n",
    "# pre-read frame\n",
    "frame_pre = stream.read()\n",
    "print(\"video resolution is (height, width, channel) : \",frame_pre.shape)\n",
    "bgr_pre = cv2.cvtColor(frame_pre, cv2.COLOR_BGR2GRAY)\n",
    "# initial hsv\n",
    "hsv = np.zeros_like(frame_pre)  \n",
    "# hsv = np.zeros_like(frame_pre[roi_rect[2]:roi_rect[3],roi_rect[0]:roi_rect[1]])  \n",
    "hsv[...,1] = 255 #saturation is full\n",
    "blank = np.zeros_like(frame_pre)\n",
    "\n",
    "# video loop\n",
    "count = 0\n",
    "print(\"begin stream!\")\n",
    "\n",
    "\n",
    "cv2.arrowedLine(frame_pre,(100,100), (80,80), color = (0, 255, 0), thickness=2, line_type=0, shift=0, tipLength=0.2)\n",
    "cv2.imshow(\"test\", cv2.resize(frame_pre, [800, 600]))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "[[ 3.5  4.5  5.5]\n",
      " [ 7.5  8.5  9.5]\n",
      " [11.5 12.5 13.5]\n",
      " [15.5 16.5 17.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(1, 21).reshape(5, 4)\n",
    "w = np.ones((2, 2)) /4\n",
    "\n",
    "\n",
    "\n",
    "z = my_conv(x, w, 1)\n",
    "print(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps:  24.995066763138855\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m     cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m     55\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 57\u001b[0m video_flag()\n",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m, in \u001b[0;36mvideo_flag\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m\"\u001b[39m, frame)\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m2000\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39m27\u001b[39m:\n\u001b[0;32m     53\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     54\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pylab import *\n",
    "from PIL import Image\n",
    "import sys\n",
    "import copy\n",
    "input_img = \"./WIN_20230329_16_13_08_Pro.mp4\"\n",
    "#例如E:\\demo\\1.jpg\n",
    "\n",
    "def rgb2hex(rgb_list):\n",
    "    #rgb_list = bgr_list[::-1]\n",
    "    #print(rgb_list)\n",
    "    res = \"#\"\n",
    "    for a in rgb_list:\n",
    "        a_hex = hex(a)\n",
    "        if a<16:\n",
    "            res+=\"0\"\n",
    "            res+= a_hex[2:]\n",
    "        else:\n",
    "            res+= a_hex[2:]\n",
    "    return res\n",
    "            \n",
    "        \n",
    "def video_flag():\n",
    "    frame = 0\n",
    "    cap = cv2.VideoCapture(input_img)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"fps: \", fps)\n",
    "    # frame=cv2.imread('E:/temp/vlcsnap-2020-09-11-17h35m32s537.png')\n",
    "\n",
    "    def on_EVENT_LBUTTONDOWN(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            xy = \"%d,%d\" % (x, y)\n",
    "            cv2.circle(frame, (x-1, y-1), 1, (255, 0, 0), thickness = -1)\n",
    "            cv2.putText(frame, xy, (x+10, y+10), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        3.0, (0,0,0), thickness = 3)\n",
    "            print(\"x:{},y:{}\".format(x,y))\n",
    "            bgr_list = frame[y, x]\n",
    "            rgb_list = bgr_list[::-1]\n",
    "            print(\"RGB为: \", rgb_list)\n",
    "            print(\"十六进制颜色：\", rgb2hex(rgb_list))\n",
    "            print(\"--\"*20)\n",
    "            cv2.imshow(\"video\", frame)\n",
    "    cv2.namedWindow('video', cv2.WINDOW_NORMAL)\n",
    "    cv2.setMouseCallback(\"video\", on_EVENT_LBUTTONDOWN)\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            print(\"video play over!\")\n",
    "            break\n",
    "        cv2.imshow(\"video\", frame)\n",
    "        if cv2.waitKey(2000) & 0xFF == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "video_flag()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8bd9ababa4d801eca6d0218de7fd3834fbea04c1af3d9ce5aafada0f0daf03c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
